{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ef4830-85f4-427b-a1c0-788b461dc932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Update the paths to your local image files\n",
    "content_path = \"/content/0d8d25d54fa42ac72093451e68d8ffb83af1af81.jpg\"\n",
    "style_path = \"/content/Vasiliy_Kandinskiy_22.jpg\"\n",
    "\n",
    "# Desired size for images\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# Function to load and process image\n",
    "def load_and_process_image(image_path):\n",
    "    img = load_img(image_path, target_size=IMG_SIZE)\n",
    "    img = img_to_array(img)\n",
    "    img = preprocess_input(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "# Function to deprocess image\n",
    "def deprocess(img):\n",
    "    img[:, :, 0] += 103.939\n",
    "    img[:, :, 1] += 116.779\n",
    "    img[:, :, 2] += 123.68\n",
    "    img = img[:, :, ::-1]\n",
    "    img = np.clip(img, 0, 255).astype('uint8')\n",
    "    return img\n",
    "\n",
    "# Function to display image\n",
    "def display_image(image):\n",
    "    if len(image.shape) == 4:\n",
    "        img = np.squeeze(image, axis=0)\n",
    "    img = deprocess(img)\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "# Load content and style images\n",
    "content_img = load_and_process_image(content_path)\n",
    "display_image(content_img)\n",
    "\n",
    "style_img = load_and_process_image(style_path)\n",
    "display_image(style_img)\n",
    "\n",
    "# Initialize VGG19 model\n",
    "model = VGG19(include_top=False, weights='imagenet')\n",
    "model.trainable = False\n",
    "model.summary()\n",
    "\n",
    "# Define content model\n",
    "content_layer = 'block5_conv2'\n",
    "content_model = Model(inputs=model.input, outputs=model.get_layer(content_layer).output)\n",
    "content_model.summary()\n",
    "\n",
    "# Define style model\n",
    "style_layers = ['block1_conv1', 'block3_conv1', 'block5_conv1']\n",
    "style_models = [Model(inputs=model.input, outputs=model.get_layer(layer).output) for layer in style_layers]\n",
    "\n",
    "# Content loss function\n",
    "def content_cost(content, generated):\n",
    "    a_C = content_model(content)\n",
    "    a_G = content_model(generated)\n",
    "    loss = tf.reduce_mean(tf.square(a_C - a_G))\n",
    "    return loss\n",
    "\n",
    "# Gram matrix function\n",
    "def gram_matrix(A):\n",
    "    channels = int(A.shape[-1])\n",
    "    a = tf.reshape(A, [-1, channels])\n",
    "    n = tf.shape(a)[0]\n",
    "    gram = tf.matmul(a, a, transpose_a=True)\n",
    "    return gram / tf.cast(n, tf.float32)\n",
    "\n",
    "# Style loss function\n",
    "def style_cost(style, generated):\n",
    "    J_style = 0\n",
    "    weight_of_layer = 1. / len(style_models)\n",
    "    for style_model in style_models:\n",
    "        a_S = style_model(style)\n",
    "        a_G = style_model(generated)\n",
    "        GS = gram_matrix(a_S)\n",
    "        GG = gram_matrix(a_G)\n",
    "        style_loss = tf.reduce_mean(tf.square(GS - GG))\n",
    "        J_style += style_loss * weight_of_layer\n",
    "    return J_style\n",
    "\n",
    "# Training function\n",
    "generated_images = []\n",
    "\n",
    "def training_loop(content_path, style_path, iterations=50, a=10, b=1000):\n",
    "    content = load_and_process_image(content_path)\n",
    "    style = load_and_process_image(style_path)\n",
    "    generated = tf.Variable(content, dtype=tf.float32)\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=7)\n",
    "\n",
    "    best_cost = math.inf\n",
    "    best_image = None\n",
    "    for i in range(iterations):\n",
    "        start_time_cpu = time.process_time()\n",
    "        start_time_wall = time.time()\n",
    "        with tf.GradientTape() as tape:\n",
    "            J_content = content_cost(content, generated)\n",
    "            J_style = style_cost(style, generated)\n",
    "            J_total = a * J_content + b * J_style\n",
    "\n",
    "        grads = tape.gradient(J_total, generated)\n",
    "        opt.apply_gradients([(grads, generated)])\n",
    "\n",
    "        end_time_cpu = time.process_time()\n",
    "        end_time_wall = time.time()\n",
    "        cpu_time = end_time_cpu - start_time_cpu\n",
    "        wall_time = end_time_wall - start_time_wall\n",
    "\n",
    "        if J_total < best_cost:\n",
    "            best_cost = J_total\n",
    "            best_image = generated.numpy()\n",
    "\n",
    "        print(f\"Iteration {i}:\")\n",
    "        print(f\"Content Loss: {J_content:.2e}\")\n",
    "        print(f\"Style Loss: {J_style:.2e}\")\n",
    "        print(f\"Total Loss: {J_total:.2e}\")\n",
    "        print(f\"CPU Time: {cpu_time:.2f} s\")\n",
    "        print(f\"Wall Time: {wall_time:.2f} s\")\n",
    "\n",
    "        generated_images.append(generated.numpy())\n",
    "\n",
    "    return best_image\n",
    "\n",
    "# Train the model and get the best image\n",
    "final_img = training_loop(content_path, style_path)\n",
    "display_image(final_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba34fd0c-b9fe-489a-8c33-331d68b805d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\\n80134624/80134624 [==============================] - 0s 0us/step\\nModel: \"vgg19\"\\n_________________________________________________________________\\n Layer (type)                Output Shape              Param #   \\n=================================================================\\n input_1 (InputLayer)        [(None, None, None, 3)]   0         \\n                                                                 \\n block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \\n                                                                 \\n block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \\n                                                                 \\n block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \\n                                                                 \\n block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \\n                                                                 \\n block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \\n                                                                 \\n block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \\n                                                                 \\n block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \\n                                                                 \\n block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \\n                                                                 \\n block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \\n                                                                 \\n block3_conv4 (Conv2D)       (None, None, None, 256)   590080    \\n                                                                 \\n block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \\n                                                                 \\n block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \\n                                                                 \\n block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \\n                                                                 \\n block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \\n                                                                 \\n block4_conv4 (Conv2D)       (None, None, None, 512)   2359808   \\n                                                                 \\n block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \\n                                                                 \\n block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \\n                                                                 \\n block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \\n                                                                 \\n block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \\n                                                                 \\n block5_conv4 (Conv2D)       (None, None, None, 512)   2359808   \\n                                                                 \\n block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \\n                                                                 \\n=================================================================\\nTotal params: 20024384 (76.39 MB)\\nTrainable params: 0 (0.00 Byte)\\nNon-trainable params: 20024384 (76.39 MB)\\n_________________________________________________________________\\nModel: \"model\"\\n_________________________________________________________________\\n Layer (type)                Output Shape              Param #   \\n=================================================================\\n input_1 (InputLayer)        [(None, None, None, 3)]   0         \\n                                                                 \\n block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \\n                                                                 \\n block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \\n                                                                 \\n block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \\n                                                                 \\n block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \\n                                                                 \\n block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \\n                                                                 \\n block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \\n                                                                 \\n block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \\n                                                                 \\n block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \\n                                                                 \\n block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \\n                                                                 \\n block3_conv4 (Conv2D)       (None, None, None, 256)   590080    \\n                                                                 \\n block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \\n                                                                 \\n block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \\n                                                                 \\n block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \\n                                                                 \\n block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \\n                                                                 \\n block4_conv4 (Conv2D)       (None, None, None, 512)   2359808   \\n                                                                 \\n block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \\n                                                                 \\n block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \\n                                                                 \\n block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \\n                                                                 \\n=================================================================\\nTotal params: 15304768 (58.38 MB)\\nTrainable params: 0 (0.00 Byte)\\nNon-trainable params: 15304768 (58.38 MB)\\n_________________________________________________________________\\nIteration 0:\\nContent Loss: 0.00e+00\\nStyle Loss: 5.16e+08\\nTotal Loss: 5.16e+11\\nCPU Time: 20.83 s\\nWall Time: 14.28 s\\nIteration 1:\\nContent Loss: 4.59e+02\\nStyle Loss: 2.98e+08\\nTotal Loss: 2.98e+11\\nCPU Time: 20.42 s\\nWall Time: 13.08 s\\nIteration 2:\\nContent Loss: 1.36e+03\\nStyle Loss: 2.13e+08\\nTotal Loss: 2.13e+11\\nCPU Time: 20.23 s\\nWall Time: 12.92 s\\nIteration 3:\\nContent Loss: 1.99e+03\\nStyle Loss: 1.75e+08\\nTotal Loss: 1.75e+11\\nCPU Time: 20.40 s\\nWall Time: 13.12 s\\nIteration 4:\\nContent Loss: 2.32e+03\\nStyle Loss: 1.55e+08\\nTotal Loss: 1.55e+11\\nCPU Time: 20.17 s\\nWall Time: 12.79 s\\nIteration 5:\\nContent Loss: 2.44e+03\\nStyle Loss: 1.37e+08\\nTotal Loss: 1.37e+11\\nCPU Time: 20.77 s\\nWall Time: 13.10 s\\nIteration 6:\\nContent Loss: 2.53e+03\\nStyle Loss: 1.21e+08\\nTotal Loss: 1.21e+11\\nCPU Time: 20.54 s\\nWall Time: 12.44 s\\nIteration 7:\\nContent Loss: 2.66e+03\\nStyle Loss: 1.09e+08\\nTotal Loss: 1.09e+11\\nCPU Time: 20.37 s\\nWall Time: 13.15 s\\nIteration 8:\\nContent Loss: 2.83e+03\\nStyle Loss: 9.88e+07\\nTotal Loss: 9.88e+10\\nCPU Time: 20.47 s\\nWall Time: 12.54 s\\nIteration 9:\\nContent Loss: 3.00e+03\\nStyle Loss: 9.01e+07\\nTotal Loss: 9.01e+10\\nCPU Time: 20.53 s\\nWall Time: 13.04 s\\nIteration 10:\\nContent Loss: 3.14e+03\\nStyle Loss: 8.27e+07\\nTotal Loss: 8.27e+10\\nCPU Time: 20.42 s\\nWall Time: 13.23 s\\nIteration 11:\\nContent Loss: 3.24e+03\\nStyle Loss: 7.65e+07\\nTotal Loss: 7.65e+10\\nCPU Time: 20.29 s\\nWall Time: 13.17 s\\nIteration 12:\\nContent Loss: 3.29e+03\\nStyle Loss: 7.12e+07\\nTotal Loss: 7.12e+10\\nCPU Time: 20.04 s\\nWall Time: 12.88 s\\nIteration 13:\\nContent Loss: 3.30e+03\\nStyle Loss: 6.63e+07\\nTotal Loss: 6.63e+10\\nCPU Time: 20.09 s\\nWall Time: 15.68 s\\nIteration 14:\\nContent Loss: 3.30e+03\\nStyle Loss: 6.20e+07\\nTotal Loss: 6.20e+10\\nCPU Time: 20.25 s\\nWall Time: 13.05 s\\nIteration 15:\\nContent Loss: 3.32e+03\\nStyle Loss: 5.80e+07\\nTotal Loss: 5.80e+10\\nCPU Time: 20.40 s\\nWall Time: 13.06 s\\nIteration 16:\\nContent Loss: 3.36e+03\\nStyle Loss: 5.46e+07\\nTotal Loss: 5.46e+10\\nCPU Time: 20.60 s\\nWall Time: 13.16 s\\nIteration 17:\\nContent Loss: 3.41e+03\\nStyle Loss: 5.15e+07\\nTotal Loss: 5.15e+10\\nCPU Time: 20.11 s\\nWall Time: 12.92 s\\nIteration 18:\\nContent Loss: 3.46e+03\\nStyle Loss: 4.88e+07\\nTotal Loss: 4.88e+10\\nCPU Time: 20.16 s\\nWall Time: 12.98 s\\nIteration 19:\\nContent Loss: 3.51e+03\\nStyle Loss: 4.63e+07\\nTotal Loss: 4.63e+10\\nCPU Time: 20.57 s\\nWall Time: 13.14 s\\nIteration 20:\\nContent Loss: 3.56e+03\\nStyle Loss: 4.41e+07\\nTotal Loss: 4.41e+10\\nCPU Time: 20.63 s\\nWall Time: 12.90 s\\nIteration 21:\\nContent Loss: 3.61e+03\\nStyle Loss: 4.21e+07\\nTotal Loss: 4.21e+10\\nCPU Time: 20.54 s\\nWall Time: 12.84 s\\nIteration 22:\\nContent Loss: 3.66e+03\\nStyle Loss: 4.02e+07\\nTotal Loss: 4.02e+10\\nCPU Time: 20.87 s\\nWall Time: 12.77 s\\nIteration 23:\\nContent Loss: 3.71e+03\\nStyle Loss: 3.84e+07\\nTotal Loss: 3.84e+10\\nCPU Time: 20.62 s\\nWall Time: 12.59 s\\nIteration 24:\\nContent Loss: 3.77e+03\\nStyle Loss: 3.68e+07\\nTotal Loss: 3.68e+10\\nCPU Time: 20.61 s\\nWall Time: 12.85 s\\nIteration 25:\\nContent Loss: 3.83e+03\\nStyle Loss: 3.53e+07\\nTotal Loss: 3.53e+10\\nCPU Time: 20.33 s\\nWall Time: 13.21 s\\nIteration 26:\\nContent Loss: 3.90e+03\\nStyle Loss: 3.40e+07\\nTotal Loss: 3.40e+10\\nCPU Time: 20.22 s\\nWall Time: 13.09 s\\nIteration 27:\\nContent Loss: 3.96e+03\\nStyle Loss: 3.27e+07\\nTotal Loss: 3.27e+10\\nCPU Time: 20.38 s\\nWall Time: 13.18 s\\nIteration 28:\\nContent Loss: 4.01e+03\\nStyle Loss: 3.15e+07\\nTotal Loss: 3.15e+10\\nCPU Time: 20.41 s\\nWall Time: 13.12 s\\nIteration 29:\\nContent Loss: 4.06e+03\\nStyle Loss: 3.04e+07\\nTotal Loss: 3.04e+10\\nCPU Time: 20.47 s\\nWall Time: 13.13 s\\nIteration 30:\\nContent Loss: 4.11e+03\\nStyle Loss: 2.94e+07\\nTotal Loss: 2.94e+10\\nCPU Time: 20.20 s\\nWall Time: 12.88 s\\nIteration 31:\\nContent Loss: 4.16e+03\\nStyle Loss: 2.84e+07\\nTotal Loss: 2.84e+10\\nCPU Time: 20.43 s\\nWall Time: 13.08 s\\nIteration 32:\\nContent Loss: 4.20e+03\\nStyle Loss: 2.75e+07\\nTotal Loss: 2.75e+10\\nCPU Time: 20.59 s\\nWall Time: 13.22 s\\nIteration 33:\\nContent Loss: 4.24e+03\\nStyle Loss: 2.66e+07\\nTotal Loss: 2.66e+10\\nCPU Time: 20.41 s\\nWall Time: 13.00 s\\nIteration 34:\\nContent Loss: 4.28e+03\\nStyle Loss: 2.58e+07\\nTotal Loss: 2.58e+10\\nCPU Time: 19.81 s\\nWall Time: 14.39 s\\nIteration 35:\\nContent Loss: 4.31e+03\\nStyle Loss: 2.50e+07\\nTotal Loss: 2.50e+10\\nCPU Time: 24.91 s\\nWall Time: 16.97 s\\nIteration 36:\\nContent Loss: 4.34e+03\\nStyle Loss: 2.43e+07\\nTotal Loss: 2.43e+10\\nCPU Time: 21.18 s\\nWall Time: 14.60 s\\nIteration 37:\\nContent Loss: 4.38e+03\\nStyle Loss: 2.36e+07\\nTotal Loss: 2.36e+10\\nCPU Time: 20.64 s\\nWall Time: 13.26 s\\nIteration 38:\\nContent Loss: 4.41e+03\\nStyle Loss: 2.29e+07\\nTotal Loss: 2.29e+10\\nCPU Time: 20.18 s\\nWall Time: 12.97 s\\nIteration 39:\\nContent Loss: 4.45e+03\\nStyle Loss: 2.23e+07\\nTotal Loss: 2.23e+10\\nCPU Time: 20.49 s\\nWall Time: 13.04 s\\nIteration 40:\\nContent Loss: 4.48e+03\\nStyle Loss: 2.17e+07\\nTotal Loss: 2.17e+10\\nCPU Time: 20.53 s\\nWall Time: 13.05 s\\nIteration 41:\\nContent Loss: 4.51e+03\\nStyle Loss: 2.11e+07\\nTotal Loss: 2.11e+10\\nCPU Time: 22.48 s\\nWall Time: 14.30 s\\nIteration 42:\\nContent Loss: 4.54e+03\\nStyle Loss: 2.06e+07\\nTotal Loss: 2.06e+10\\nCPU Time: 20.85 s\\nWall Time: 13.31 s\\nIteration 43:\\nContent Loss: 4.57e+03\\nStyle Loss: 2.00e+07\\nTotal Loss: 2.00e+10\\nCPU Time: 21.00 s\\nWall Time: 12.96 s\\nIteration 44:\\nContent Loss: 4.58e+03\\nStyle Loss: 1.95e+07\\nTotal Loss: 1.95e+10\\nCPU Time: 21.02 s\\nWall Time: 12.93 s\\nIteration 45:\\nContent Loss: 4.60e+03\\nStyle Loss: 1.91e+07\\nTotal Loss: 1.91e+10\\nCPU Time: 20.99 s\\nWall Time: 13.07 s\\nIteration 46:\\nContent Loss: 4.61e+03\\nStyle Loss: 1.86e+07\\nTotal Loss: 1.86e+10\\nCPU Time: 20.88 s\\nWall Time: 13.07 s\\nIteration 47:\\nContent Loss: 4.63e+03\\nStyle Loss: 1.82e+07\\nTotal Loss: 1.82e+10\\nCPU Time: 20.71 s\\nWall Time: 13.12 s\\nIteration 48:\\nContent Loss: 4.65e+03\\nStyle Loss: 1.78e+07\\nTotal Loss: 1.78e+10\\nCPU Time: 20.42 s\\nWall Time: 13.21 s\\nIteration 49:\\nContent Loss: 4.67e+03\\nStyle Loss: 1.74e+07\\nTotal Loss: 1.74e+10\\nCPU Time: 20.43 s\\nWall Time: 13.28 s\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "80134624/80134624 [==============================] - 0s 0us/step\n",
    "Model: \"vgg19\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
    "                                                                 \n",
    " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
    "                                                                 \n",
    " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
    "                                                                 \n",
    " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
    "                                                                 \n",
    " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
    "                                                                 \n",
    " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
    "                                                                 \n",
    " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
    "                                                                 \n",
    " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
    "                                                                 \n",
    " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
    "                                                                 \n",
    " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
    "                                                                 \n",
    " block3_conv4 (Conv2D)       (None, None, None, 256)   590080    \n",
    "                                                                 \n",
    " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
    "                                                                 \n",
    " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
    "                                                                 \n",
    " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
    "                                                                 \n",
    " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
    "                                                                 \n",
    " block4_conv4 (Conv2D)       (None, None, None, 512)   2359808   \n",
    "                                                                 \n",
    " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
    "                                                                 \n",
    " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
    "                                                                 \n",
    " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
    "                                                                 \n",
    " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
    "                                                                 \n",
    " block5_conv4 (Conv2D)       (None, None, None, 512)   2359808   \n",
    "                                                                 \n",
    " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 20024384 (76.39 MB)\n",
    "Trainable params: 0 (0.00 Byte)\n",
    "Non-trainable params: 20024384 (76.39 MB)\n",
    "_________________________________________________________________\n",
    "Model: \"model\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
    "                                                                 \n",
    " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
    "                                                                 \n",
    " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
    "                                                                 \n",
    " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
    "                                                                 \n",
    " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
    "                                                                 \n",
    " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
    "                                                                 \n",
    " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
    "                                                                 \n",
    " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
    "                                                                 \n",
    " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
    "                                                                 \n",
    " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
    "                                                                 \n",
    " block3_conv4 (Conv2D)       (None, None, None, 256)   590080    \n",
    "                                                                 \n",
    " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
    "                                                                 \n",
    " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
    "                                                                 \n",
    " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
    "                                                                 \n",
    " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
    "                                                                 \n",
    " block4_conv4 (Conv2D)       (None, None, None, 512)   2359808   \n",
    "                                                                 \n",
    " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
    "                                                                 \n",
    " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
    "                                                                 \n",
    " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 15304768 (58.38 MB)\n",
    "Trainable params: 0 (0.00 Byte)\n",
    "Non-trainable params: 15304768 (58.38 MB)\n",
    "_________________________________________________________________\n",
    "Iteration 0:\n",
    "Content Loss: 0.00e+00\n",
    "Style Loss: 5.16e+08\n",
    "Total Loss: 5.16e+11\n",
    "CPU Time: 20.83 s\n",
    "Wall Time: 14.28 s\n",
    "Iteration 1:\n",
    "Content Loss: 4.59e+02\n",
    "Style Loss: 2.98e+08\n",
    "Total Loss: 2.98e+11\n",
    "CPU Time: 20.42 s\n",
    "Wall Time: 13.08 s\n",
    "Iteration 2:\n",
    "Content Loss: 1.36e+03\n",
    "Style Loss: 2.13e+08\n",
    "Total Loss: 2.13e+11\n",
    "CPU Time: 20.23 s\n",
    "Wall Time: 12.92 s\n",
    "Iteration 3:\n",
    "Content Loss: 1.99e+03\n",
    "Style Loss: 1.75e+08\n",
    "Total Loss: 1.75e+11\n",
    "CPU Time: 20.40 s\n",
    "Wall Time: 13.12 s\n",
    "Iteration 4:\n",
    "Content Loss: 2.32e+03\n",
    "Style Loss: 1.55e+08\n",
    "Total Loss: 1.55e+11\n",
    "CPU Time: 20.17 s\n",
    "Wall Time: 12.79 s\n",
    "Iteration 5:\n",
    "Content Loss: 2.44e+03\n",
    "Style Loss: 1.37e+08\n",
    "Total Loss: 1.37e+11\n",
    "CPU Time: 20.77 s\n",
    "Wall Time: 13.10 s\n",
    "Iteration 6:\n",
    "Content Loss: 2.53e+03\n",
    "Style Loss: 1.21e+08\n",
    "Total Loss: 1.21e+11\n",
    "CPU Time: 20.54 s\n",
    "Wall Time: 12.44 s\n",
    "Iteration 7:\n",
    "Content Loss: 2.66e+03\n",
    "Style Loss: 1.09e+08\n",
    "Total Loss: 1.09e+11\n",
    "CPU Time: 20.37 s\n",
    "Wall Time: 13.15 s\n",
    "Iteration 8:\n",
    "Content Loss: 2.83e+03\n",
    "Style Loss: 9.88e+07\n",
    "Total Loss: 9.88e+10\n",
    "CPU Time: 20.47 s\n",
    "Wall Time: 12.54 s\n",
    "Iteration 9:\n",
    "Content Loss: 3.00e+03\n",
    "Style Loss: 9.01e+07\n",
    "Total Loss: 9.01e+10\n",
    "CPU Time: 20.53 s\n",
    "Wall Time: 13.04 s\n",
    "Iteration 10:\n",
    "Content Loss: 3.14e+03\n",
    "Style Loss: 8.27e+07\n",
    "Total Loss: 8.27e+10\n",
    "CPU Time: 20.42 s\n",
    "Wall Time: 13.23 s\n",
    "Iteration 11:\n",
    "Content Loss: 3.24e+03\n",
    "Style Loss: 7.65e+07\n",
    "Total Loss: 7.65e+10\n",
    "CPU Time: 20.29 s\n",
    "Wall Time: 13.17 s\n",
    "Iteration 12:\n",
    "Content Loss: 3.29e+03\n",
    "Style Loss: 7.12e+07\n",
    "Total Loss: 7.12e+10\n",
    "CPU Time: 20.04 s\n",
    "Wall Time: 12.88 s\n",
    "Iteration 13:\n",
    "Content Loss: 3.30e+03\n",
    "Style Loss: 6.63e+07\n",
    "Total Loss: 6.63e+10\n",
    "CPU Time: 20.09 s\n",
    "Wall Time: 15.68 s\n",
    "Iteration 14:\n",
    "Content Loss: 3.30e+03\n",
    "Style Loss: 6.20e+07\n",
    "Total Loss: 6.20e+10\n",
    "CPU Time: 20.25 s\n",
    "Wall Time: 13.05 s\n",
    "Iteration 15:\n",
    "Content Loss: 3.32e+03\n",
    "Style Loss: 5.80e+07\n",
    "Total Loss: 5.80e+10\n",
    "CPU Time: 20.40 s\n",
    "Wall Time: 13.06 s\n",
    "Iteration 16:\n",
    "Content Loss: 3.36e+03\n",
    "Style Loss: 5.46e+07\n",
    "Total Loss: 5.46e+10\n",
    "CPU Time: 20.60 s\n",
    "Wall Time: 13.16 s\n",
    "Iteration 17:\n",
    "Content Loss: 3.41e+03\n",
    "Style Loss: 5.15e+07\n",
    "Total Loss: 5.15e+10\n",
    "CPU Time: 20.11 s\n",
    "Wall Time: 12.92 s\n",
    "Iteration 18:\n",
    "Content Loss: 3.46e+03\n",
    "Style Loss: 4.88e+07\n",
    "Total Loss: 4.88e+10\n",
    "CPU Time: 20.16 s\n",
    "Wall Time: 12.98 s\n",
    "Iteration 19:\n",
    "Content Loss: 3.51e+03\n",
    "Style Loss: 4.63e+07\n",
    "Total Loss: 4.63e+10\n",
    "CPU Time: 20.57 s\n",
    "Wall Time: 13.14 s\n",
    "Iteration 20:\n",
    "Content Loss: 3.56e+03\n",
    "Style Loss: 4.41e+07\n",
    "Total Loss: 4.41e+10\n",
    "CPU Time: 20.63 s\n",
    "Wall Time: 12.90 s\n",
    "Iteration 21:\n",
    "Content Loss: 3.61e+03\n",
    "Style Loss: 4.21e+07\n",
    "Total Loss: 4.21e+10\n",
    "CPU Time: 20.54 s\n",
    "Wall Time: 12.84 s\n",
    "Iteration 22:\n",
    "Content Loss: 3.66e+03\n",
    "Style Loss: 4.02e+07\n",
    "Total Loss: 4.02e+10\n",
    "CPU Time: 20.87 s\n",
    "Wall Time: 12.77 s\n",
    "Iteration 23:\n",
    "Content Loss: 3.71e+03\n",
    "Style Loss: 3.84e+07\n",
    "Total Loss: 3.84e+10\n",
    "CPU Time: 20.62 s\n",
    "Wall Time: 12.59 s\n",
    "Iteration 24:\n",
    "Content Loss: 3.77e+03\n",
    "Style Loss: 3.68e+07\n",
    "Total Loss: 3.68e+10\n",
    "CPU Time: 20.61 s\n",
    "Wall Time: 12.85 s\n",
    "Iteration 25:\n",
    "Content Loss: 3.83e+03\n",
    "Style Loss: 3.53e+07\n",
    "Total Loss: 3.53e+10\n",
    "CPU Time: 20.33 s\n",
    "Wall Time: 13.21 s\n",
    "Iteration 26:\n",
    "Content Loss: 3.90e+03\n",
    "Style Loss: 3.40e+07\n",
    "Total Loss: 3.40e+10\n",
    "CPU Time: 20.22 s\n",
    "Wall Time: 13.09 s\n",
    "Iteration 27:\n",
    "Content Loss: 3.96e+03\n",
    "Style Loss: 3.27e+07\n",
    "Total Loss: 3.27e+10\n",
    "CPU Time: 20.38 s\n",
    "Wall Time: 13.18 s\n",
    "Iteration 28:\n",
    "Content Loss: 4.01e+03\n",
    "Style Loss: 3.15e+07\n",
    "Total Loss: 3.15e+10\n",
    "CPU Time: 20.41 s\n",
    "Wall Time: 13.12 s\n",
    "Iteration 29:\n",
    "Content Loss: 4.06e+03\n",
    "Style Loss: 3.04e+07\n",
    "Total Loss: 3.04e+10\n",
    "CPU Time: 20.47 s\n",
    "Wall Time: 13.13 s\n",
    "Iteration 30:\n",
    "Content Loss: 4.11e+03\n",
    "Style Loss: 2.94e+07\n",
    "Total Loss: 2.94e+10\n",
    "CPU Time: 20.20 s\n",
    "Wall Time: 12.88 s\n",
    "Iteration 31:\n",
    "Content Loss: 4.16e+03\n",
    "Style Loss: 2.84e+07\n",
    "Total Loss: 2.84e+10\n",
    "CPU Time: 20.43 s\n",
    "Wall Time: 13.08 s\n",
    "Iteration 32:\n",
    "Content Loss: 4.20e+03\n",
    "Style Loss: 2.75e+07\n",
    "Total Loss: 2.75e+10\n",
    "CPU Time: 20.59 s\n",
    "Wall Time: 13.22 s\n",
    "Iteration 33:\n",
    "Content Loss: 4.24e+03\n",
    "Style Loss: 2.66e+07\n",
    "Total Loss: 2.66e+10\n",
    "CPU Time: 20.41 s\n",
    "Wall Time: 13.00 s\n",
    "Iteration 34:\n",
    "Content Loss: 4.28e+03\n",
    "Style Loss: 2.58e+07\n",
    "Total Loss: 2.58e+10\n",
    "CPU Time: 19.81 s\n",
    "Wall Time: 14.39 s\n",
    "Iteration 35:\n",
    "Content Loss: 4.31e+03\n",
    "Style Loss: 2.50e+07\n",
    "Total Loss: 2.50e+10\n",
    "CPU Time: 24.91 s\n",
    "Wall Time: 16.97 s\n",
    "Iteration 36:\n",
    "Content Loss: 4.34e+03\n",
    "Style Loss: 2.43e+07\n",
    "Total Loss: 2.43e+10\n",
    "CPU Time: 21.18 s\n",
    "Wall Time: 14.60 s\n",
    "Iteration 37:\n",
    "Content Loss: 4.38e+03\n",
    "Style Loss: 2.36e+07\n",
    "Total Loss: 2.36e+10\n",
    "CPU Time: 20.64 s\n",
    "Wall Time: 13.26 s\n",
    "Iteration 38:\n",
    "Content Loss: 4.41e+03\n",
    "Style Loss: 2.29e+07\n",
    "Total Loss: 2.29e+10\n",
    "CPU Time: 20.18 s\n",
    "Wall Time: 12.97 s\n",
    "Iteration 39:\n",
    "Content Loss: 4.45e+03\n",
    "Style Loss: 2.23e+07\n",
    "Total Loss: 2.23e+10\n",
    "CPU Time: 20.49 s\n",
    "Wall Time: 13.04 s\n",
    "Iteration 40:\n",
    "Content Loss: 4.48e+03\n",
    "Style Loss: 2.17e+07\n",
    "Total Loss: 2.17e+10\n",
    "CPU Time: 20.53 s\n",
    "Wall Time: 13.05 s\n",
    "Iteration 41:\n",
    "Content Loss: 4.51e+03\n",
    "Style Loss: 2.11e+07\n",
    "Total Loss: 2.11e+10\n",
    "CPU Time: 22.48 s\n",
    "Wall Time: 14.30 s\n",
    "Iteration 42:\n",
    "Content Loss: 4.54e+03\n",
    "Style Loss: 2.06e+07\n",
    "Total Loss: 2.06e+10\n",
    "CPU Time: 20.85 s\n",
    "Wall Time: 13.31 s\n",
    "Iteration 43:\n",
    "Content Loss: 4.57e+03\n",
    "Style Loss: 2.00e+07\n",
    "Total Loss: 2.00e+10\n",
    "CPU Time: 21.00 s\n",
    "Wall Time: 12.96 s\n",
    "Iteration 44:\n",
    "Content Loss: 4.58e+03\n",
    "Style Loss: 1.95e+07\n",
    "Total Loss: 1.95e+10\n",
    "CPU Time: 21.02 s\n",
    "Wall Time: 12.93 s\n",
    "Iteration 45:\n",
    "Content Loss: 4.60e+03\n",
    "Style Loss: 1.91e+07\n",
    "Total Loss: 1.91e+10\n",
    "CPU Time: 20.99 s\n",
    "Wall Time: 13.07 s\n",
    "Iteration 46:\n",
    "Content Loss: 4.61e+03\n",
    "Style Loss: 1.86e+07\n",
    "Total Loss: 1.86e+10\n",
    "CPU Time: 20.88 s\n",
    "Wall Time: 13.07 s\n",
    "Iteration 47:\n",
    "Content Loss: 4.63e+03\n",
    "Style Loss: 1.82e+07\n",
    "Total Loss: 1.82e+10\n",
    "CPU Time: 20.71 s\n",
    "Wall Time: 13.12 s\n",
    "Iteration 48:\n",
    "Content Loss: 4.65e+03\n",
    "Style Loss: 1.78e+07\n",
    "Total Loss: 1.78e+10\n",
    "CPU Time: 20.42 s\n",
    "Wall Time: 13.21 s\n",
    "Iteration 49:\n",
    "Content Loss: 4.67e+03\n",
    "Style Loss: 1.74e+07\n",
    "Total Loss: 1.74e+10\n",
    "CPU Time: 20.43 s\n",
    "Wall Time: 13.28 s\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994314b5-8a39-4da9-aebc-753ad4e24200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
